{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/rohan/Downloads/COVID-19-master/X-Ray Image DataSet/No_findings/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(41)\n",
    "data = ImageDataBunch.from_folder(path, train=\"Train\", valid =\"Valid\",\n",
    "        ds_tfms=get_transforms(), size=(256,256), bs=32, num_workers=4).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['No_findings'], 1, 400, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in training: 400\n",
      "Number of examples in validation: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples in training:\", len(data.train_ds))\n",
    "print(\"Number of examples in validation:\", len(data.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = data.one_batch()\n",
    "xb.shape,yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-36927eeb7066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Sample images from the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#Sample images from the dataset\n",
    "data.show_batch(rows=3, figsize=(10,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DarkCovidNet (modified Darknet model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(ni, nf, size=3, stride=1):\n",
    "    for_pad = lambda s: s if s > 2 else 3\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(ni, nf, kernel_size=size, stride=stride,\n",
    "                  padding=(for_pad(size) - 1)//2, bias=False), \n",
    "        nn.BatchNorm2d(nf),\n",
    "        nn.LeakyReLU(negative_slope=0.1, inplace=True)  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triple_conv(ni, nf):\n",
    "    return nn.Sequential(\n",
    "        conv_block(ni, nf),\n",
    "        conv_block(nf, ni, size=1),  \n",
    "        conv_block(ni, nf)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpooling():\n",
    "    return nn.MaxPool2d(2, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    conv_block(3, 8),\n",
    "    maxpooling(),\n",
    "    conv_block(8, 16),\n",
    "    maxpooling(),\n",
    "    triple_conv(16, 32),\n",
    "    maxpooling(),\n",
    "    triple_conv(32, 64),\n",
    "    maxpooling(),\n",
    "    triple_conv(64, 128),\n",
    "    maxpooling(),\n",
    "    triple_conv(128, 256),\n",
    "    conv_block(256, 128, size=1),\n",
    "    conv_block(128, 256),\n",
    "    conv_layer(256, 2),\n",
    "    Flatten(),\n",
    "    nn.Linear(338, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(data, model, loss_func = nn.CrossEntropyLoss(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential\n",
      "======================================================================\n",
      "Layer (type)         Output Shape         Param #    Trainable \n",
      "======================================================================\n",
      "Conv2d               [8, 256, 256]        216        True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [8, 256, 256]        16         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [8, 256, 256]        0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [8, 128, 128]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [16, 128, 128]       1,152      True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [16, 128, 128]       32         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [16, 128, 128]       0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [16, 64, 64]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [32, 64, 64]         4,608      True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [32, 64, 64]         64         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [32, 64, 64]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [16, 66, 66]         512        True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [16, 66, 66]         32         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [16, 66, 66]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [32, 66, 66]         4,608      True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [32, 66, 66]         64         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [32, 66, 66]         0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [32, 33, 33]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [64, 33, 33]         18,432     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [64, 33, 33]         128        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [64, 33, 33]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [32, 35, 35]         2,048      True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [32, 35, 35]         64         True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [32, 35, 35]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [64, 35, 35]         18,432     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [64, 35, 35]         128        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [64, 35, 35]         0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [64, 17, 17]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [128, 17, 17]        73,728     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [128, 17, 17]        256        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [128, 17, 17]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [64, 19, 19]         8,192      True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [64, 19, 19]         128        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [64, 19, 19]         0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [128, 19, 19]        73,728     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [128, 19, 19]        256        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [128, 19, 19]        0          False     \n",
      "______________________________________________________________________\n",
      "MaxPool2d            [128, 9, 9]          0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [256, 9, 9]          294,912    True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [256, 9, 9]          512        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [256, 9, 9]          0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [128, 11, 11]        32,768     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [128, 11, 11]        256        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [128, 11, 11]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [256, 11, 11]        294,912    True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [256, 11, 11]        512        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [256, 11, 11]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [128, 13, 13]        32,768     True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [128, 13, 13]        256        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [128, 13, 13]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [256, 13, 13]        294,912    True      \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [256, 13, 13]        512        True      \n",
      "______________________________________________________________________\n",
      "LeakyReLU            [256, 13, 13]        0          False     \n",
      "______________________________________________________________________\n",
      "Conv2d               [2, 13, 13]          4,608      True      \n",
      "______________________________________________________________________\n",
      "ReLU                 [2, 13, 13]          0          False     \n",
      "______________________________________________________________________\n",
      "BatchNorm2d          [2, 13, 13]          4          True      \n",
      "______________________________________________________________________\n",
      "Flatten              [338]                0          False     \n",
      "______________________________________________________________________\n",
      "Linear               [2]                  678        True      \n",
      "______________________________________________________________________\n",
      "\n",
      "Total params: 1,164,434\n",
      "Total trainable params: 1,164,434\n",
      "Total non-trainable params: 0\n",
      "Optimized with 'torch.optim.adam.Adam', betas=(0.9, 0.99)\n",
      "Using true weight decay as discussed in https://www.fast.ai/2018/07/02/adam-weight-decay/ \n",
      "Loss function : CrossEntropyLoss\n",
      "======================================================================\n",
      "Callbacks functions applied \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.342396</td>\n",
       "      <td>0.790685</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.261838</td>\n",
       "      <td>0.538252</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.218703</td>\n",
       "      <td>0.141111</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190542</td>\n",
       "      <td>0.084161</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.169056</td>\n",
       "      <td>0.091254</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162072</td>\n",
       "      <td>0.142616</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.153581</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170246</td>\n",
       "      <td>0.152644</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176809</td>\n",
       "      <td>0.166867</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.159235</td>\n",
       "      <td>0.102111</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.150246</td>\n",
       "      <td>0.113522</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.153357</td>\n",
       "      <td>0.401838</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.153655</td>\n",
       "      <td>0.131616</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.156841</td>\n",
       "      <td>0.374867</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.162700</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.159795</td>\n",
       "      <td>0.152942</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.159459</td>\n",
       "      <td>0.141324</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.161019</td>\n",
       "      <td>0.207559</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.155112</td>\n",
       "      <td>0.065025</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.155458</td>\n",
       "      <td>2.349602</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.179314</td>\n",
       "      <td>1.229718</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.195287</td>\n",
       "      <td>0.291271</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.196925</td>\n",
       "      <td>0.073678</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.202100</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.192607</td>\n",
       "      <td>1.038232</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.177863</td>\n",
       "      <td>0.185616</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.184137</td>\n",
       "      <td>1.336804</td>\n",
       "      <td>0.696000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.193698</td>\n",
       "      <td>0.628480</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.189669</td>\n",
       "      <td>0.249966</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.177783</td>\n",
       "      <td>0.338363</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.168199</td>\n",
       "      <td>0.345295</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.164081</td>\n",
       "      <td>0.204071</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.164502</td>\n",
       "      <td>0.106111</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.166969</td>\n",
       "      <td>1.205989</td>\n",
       "      <td>0.744000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.158745</td>\n",
       "      <td>0.202745</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.158186</td>\n",
       "      <td>0.259537</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.152657</td>\n",
       "      <td>0.288709</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.146856</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.151561</td>\n",
       "      <td>0.280867</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.165716</td>\n",
       "      <td>0.103903</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.166343</td>\n",
       "      <td>0.278744</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.150106</td>\n",
       "      <td>0.176087</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.150010</td>\n",
       "      <td>0.048852</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.146675</td>\n",
       "      <td>0.088746</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.145533</td>\n",
       "      <td>0.102588</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.141574</td>\n",
       "      <td>0.073790</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.128419</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.130146</td>\n",
       "      <td>0.060290</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.123069</td>\n",
       "      <td>0.145225</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.124374</td>\n",
       "      <td>0.674937</td>\n",
       "      <td>0.848000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.125998</td>\n",
       "      <td>0.068753</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.124566</td>\n",
       "      <td>0.130531</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.112710</td>\n",
       "      <td>0.135896</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.106686</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.103972</td>\n",
       "      <td>0.189634</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.091986</td>\n",
       "      <td>0.071232</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.090930</td>\n",
       "      <td>0.099528</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.089854</td>\n",
       "      <td>0.370487</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.087393</td>\n",
       "      <td>1.246959</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.082175</td>\n",
       "      <td>0.058562</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.077686</td>\n",
       "      <td>0.152681</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.071556</td>\n",
       "      <td>0.124838</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.063959</td>\n",
       "      <td>0.169453</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.075667</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.067627</td>\n",
       "      <td>0.058961</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.042776</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.065499</td>\n",
       "      <td>0.099604</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.127290</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.073240</td>\n",
       "      <td>0.055052</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.067231</td>\n",
       "      <td>0.030365</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.063005</td>\n",
       "      <td>0.042209</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.059763</td>\n",
       "      <td>0.064569</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.060667</td>\n",
       "      <td>0.094640</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.064448</td>\n",
       "      <td>0.146333</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.034066</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.058787</td>\n",
       "      <td>0.093666</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.051514</td>\n",
       "      <td>0.090718</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.050274</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.008330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.047986</td>\n",
       "      <td>0.016168</td>\n",
       "      <td>0.992000</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.044389</td>\n",
       "      <td>0.046381</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.040326</td>\n",
       "      <td>0.096681</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>0.039164</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022186</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.034318</td>\n",
       "      <td>0.045661</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.035929</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.030897</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.028993</td>\n",
       "      <td>0.033563</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.029864</td>\n",
       "      <td>0.029736</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.028585</td>\n",
       "      <td>0.026441</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>0.038474</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.029444</td>\n",
       "      <td>0.046214</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.029364</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.044169</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.031784</td>\n",
       "      <td>0.047815</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>0.050839</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.027791</td>\n",
       "      <td>0.047727</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.026208</td>\n",
       "      <td>0.052558</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(100, max_lr=3e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples in testing: 125\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of examples in testing:\", len(data.valid_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs,targets = learn.get_preds(ds_type=DatasetType.Valid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9760)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(probs,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Covid-19', 'No_findings'], 2, 500, 125)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.classes, data.c, len(data.train_ds), len(data.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 122 0.976\n",
      "[[ 21   3]\n",
      " [  0 101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Covid-19       1.00      0.88      0.93        24\n",
      " No_findings       0.97      1.00      0.99       101\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       125\n",
      "   macro avg       0.99      0.94      0.96       125\n",
      "weighted avg       0.98      0.98      0.98       125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probs = np.argmax(probs, axis=1)\n",
    "correct = 0\n",
    "for idx, pred in enumerate(probs):\n",
    "    if pred == targets[idx]:\n",
    "        correct += 1\n",
    "accuracy = correct / len(probs)\n",
    "print(len(probs), correct, accuracy)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.set_printoptions(threshold=np.inf) \n",
    "cm1 = confusion_matrix(targets, probs)\n",
    "print(cm1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "y_true1 = targets\n",
    "y_pred1 = probs\n",
    "target_names = ['Covid-19', 'No_findings']\n",
    "print(classification_report(y_true1, y_pred1, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_fig = interp.plot_confusion_matrix(return_fig=True)\n",
    "ax = cm_fig.gca()\n",
    "ax.set_ylim(interp.data.c - .5, - .5);"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Implementing Darknet19 from scratch using fast.ai - MNIST",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
